<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>EventFlow: Event-driven microservices on OpenShift (Part 1)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gTleEq_ns84/" /><category term="Containers" /><category term="Java" /><category term="JBoss A-MQ" /><category term="Microservices" /><category term="Serverless" /><category term="Stream Processing" /><category term="Apache Kafka" /><category term="cloud native" /><category term="CloudEvents" /><category term="containers" /><category term="Developer Tools" /><category term="event processing" /><category term="event-driven architecture" /><category term="EventFlow" /><category term="kubernetes" /><category term="microservices" /><category term="OpenShift Container Platform" /><category term="Red Hat AMQ" /><category term="streams" /><author><name>Hugo Hiden</name></author><id>https://developers.redhat.com/blog/?p=523017</id><updated>2018-10-15T11:00:20Z</updated><published>2018-10-15T11:00:20Z</published><content type="html">&lt;p&gt;This post is the first in a series of three related posts that describes a lightweight cloud-native distributed &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; framework we have created called EventFlow. EventFlow can be used to develop streaming applications that can process &lt;a href="https://cloudevents.io"&gt;CloudEvents&lt;/a&gt;, which are an effort to standardize upon a data format for exchanging information about events generated by cloud platforms.&lt;/p&gt; &lt;p&gt;The EventFlow platform was created to specifically target the &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;/&lt;a href="http://openshift.com/"&gt;OpenShift&lt;/a&gt; platforms, and it models event-processing applications as a connected flow or stream of components. The development of these components can be facilitated through the use of a simple SDK library, or they can be created as Docker images that can be configured using environment variables to attach to Kafka topics and process event data directly.&lt;/p&gt; &lt;p&gt;&lt;span id="more-523017"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Background&lt;/h2&gt; &lt;p&gt;Event processing is a methodology for reasoning about streams of potentially real-time events and data and generating conclusions based on both their absolute values and their temporal characteristics. Streams of events can come from many sources; they could be generated by parts of an organization (for example, patterns of orders, sales calls. etc.), they could be aggregated from external sources (for example, occurrences of news items, stock prices, etc.), collected from sensors (Internet-of-Things applications have the potential to generate vast quantities of streaming data), or even emitted by changes occurring within a cloud hosting platform.&lt;/p&gt; &lt;p&gt;Despite the attraction of being able to react in real time to streams of information, the actual process of creating and deploying event-driven systems is complex. In addition to managing the actual business logic for event processing, there are additional considerations to take into account when deploying this logic to produce a functioning system:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Code must be built and packaged in a form suitable for deployment within a container environment. This is largely dealt with using tooling such as Maven with the relevant plugins (typically, the &lt;a href="https://maven.fabric8.io/"&gt;fabric8 plugin&lt;/a&gt;). However, the responsibility of installing and connecting to the underlying messaging middleware is still the responsibility of the developer.&lt;/li&gt; &lt;li&gt;The process of modifying and scaling applications needs to be carefully managed. Adding additional compute resources to ease bottlenecks requires new resources to be brought on-stream and integrated into a running system without interfering with existing operations. Likewise, removing surplus resources needs to be done in a way that doesn’t affect the overall semantics of the application. This is particularly significant if the additional resources are located in remote cloud platforms (for example, a cloud bursting operation).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Given the benefits and challenges associated with efficiently processing event data, it is not surprising that a large number of platforms have been created.&lt;/p&gt; &lt;p&gt;It is important to realize that we made no attempt to re-create the functionality offered by libraries such as the Apache Kafka Streams API. Instead, we created a framework for connecting streaming components (some of which may themselves contain Apache Kafka Streams API code) into a coherent data flow that can be deployed and managed in a container platform.&lt;/p&gt; &lt;p&gt;Also, the framework described in this post was designed specifically to operate at scale within a container platform and was written using an entirely cloud-native approach. This approach has a number of distinct advantages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Container platforms are well suited to dealing with varying levels of load because the architecture makes it extremely easy to scale up or down parts of an application in response to different levels of demand.&lt;/li&gt; &lt;li&gt;By adopting a cloud-native first approach, we can leverage the various management, data representation, and monitoring tools that are already provided by the container platform.&lt;/li&gt; &lt;li&gt;The inherent flexibility in terms of implementation languages afforded by a platform such as OpenShift means that applications can be built using a variety of different toolkits and languages and still operate on the same stream of events.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In this post, we will focus on processing &lt;a href="https://cloudevents.io/"&gt;CloudEvents&lt;/a&gt;, which provide a standard mechanism for describing event data in a platform-independent manner. The CloudEvents specification aims to make it easier to write portable applications that produce and consume event-based services. The specification provides a base level of metadata, which might be of interest for an event, and the payload, which can be of arbitrary structure. CloudEvents are distinct from a binding to any particular serialization format, but the event-flow platform uses a &lt;a href="https://github.com/project-streamzi/jcloudevents"&gt;JSON representation&lt;/a&gt; of them. Even though we are focussing on CloudEvents in this post, the EventFlow platform is not specific to them. It can be used to transport any other type of &amp;#8220;serializable&amp;#8221; data between processors.&lt;/p&gt; &lt;h2&gt;EventFlow architecture&lt;/h2&gt; &lt;p&gt;For the purposes of the EventFlow platform, an application is modelled as a connected set of processors (P&lt;sub&gt;1&lt;/sub&gt;,P&lt;sub&gt;2,&lt;/sub&gt; and P&lt;sub&gt;3&lt;/sub&gt;). Event data flows between these processors along logical connections (C&lt;sub&gt;1&lt;/sub&gt; and C&lt;sub&gt;2&lt;/sub&gt;):&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png"&gt;&lt;img class=" aligncenter wp-image-523057 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png" alt="Diagram showing how event data flows between processors along logical connections" width="503" height="161" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png 503w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1-300x96.png 300w" sizes="(max-width: 503px) 100vw, 503px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;In order to participate in such a flow, any code written by a developer needs to fit into one of three categories:&lt;/p&gt; &lt;ul&gt; &lt;li style="list-style-type: none;"&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Data Source:&lt;/em&gt;&lt;/strong&gt; Code that falls into this category produces a stream of data that is passed to other processors via a connection. Data sources are typically located at the beginning of an event flow and can be thought of as a bridge between an external system and the stream processing application.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Data Sink:&lt;/strong&gt;&lt;/em&gt; Data Sinks receive data from other processors in a flow and act upon it without any more downstream flow operations. An example of a Data Sink could be code that receives data at the end of a flow and inserts results into a database.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Data Processor:&lt;/strong&gt;&lt;/em&gt; Data Processors act as both a Data Source and Data Sink processing a stream of input event data and producing a stream of output data. An example of a Data Processor could be an operation that filters a stream of raw data for significant events that are passed to the output stream for further downstream processing.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Because the components within a flow are deployed as OpenShift pods, we can support varying levels of message throughput, by increasing or decreasing the number of deployed pods for each component. For example, a flow containing a computationally expensive step (P&lt;sub&gt;2&lt;/sub&gt; in the figure below) could have extra replicas of the bottleneck processor deployed to cope with the throughput. (EventFlow supports replicas deployed both in the local cloud environment and/or in remote cloud environments):&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png"&gt;&lt;img class=" aligncenter wp-image-523067 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png" alt="Diagram of extra replicas of a bottleneck processor deployed to cope with the throughput" width="499" height="185" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png 499w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas-300x111.png 300w" sizes="(max-width: 499px) 100vw, 499px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In order to connect processors together and the manage the distribution of events between replicas, we make use of Apache Kafka (as provided by the &lt;a href="https://developers.redhat.com/products/amq/overview/"&gt;Red Hat AMQ Streams&lt;/a&gt; product) deployed within the container platform. For the example shown in the first figure, the two inter-processor connections (C&lt;sub&gt;1&lt;/sub&gt; and C&lt;sub&gt;2&lt;/sub&gt;) are represented using two separate Kafka topics.&lt;/p&gt; &lt;p&gt;When a flow is deployed within the container platform, the components within the flow are represented as follows:&lt;/p&gt; &lt;ul&gt; &lt;li style="list-style-type: none;"&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Flow:&lt;/strong&gt;&lt;/em&gt; The definition of the flow (whether it is created using a graphical editor or from the Kubernetes k8s API) is stored as a Custom Resource within the container platform.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Processor:&lt;/strong&gt;&lt;/em&gt; Processors are deployed as containers within OpenShift. During the process of developing a Processor, a Docker image is created and uploaded to a registry. Deployed replicas of this image are responsible for performing the actual processing tasks.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Connections:&lt;/strong&gt;&lt;/em&gt; The process of deploying the Kafka topics that represent connections within the data flow involves creating a Custom Resource for each Topic. Red Hat AMQ Streams contains an operator that responds to changes in these Custom Resources by creating, removing, or modifying the appropriate Kafka topics.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These concepts are illustrated below:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png"&gt;&lt;img class=" aligncenter wp-image-523077 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png" alt="Diagram of the components within a flow" width="880" height="521" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png 880w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full-300x178.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full-768x455.png 768w" sizes="(max-width: 880px) 100vw, 880px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Developing, designing, deploying, and managing flows&lt;/h2&gt; &lt;p&gt;Given the high-level overview presented above, making use of the event-flow platform requires developers to consider a set of tasks ranging from the development of event processing code to the management of deployed replicas and connections to remote clouds.&lt;/p&gt; &lt;h3&gt;Develop: Maven archetypes for developing processors&lt;/h3&gt; &lt;p&gt;Maven archetypes can be used to provide scaffolding for developers creating processors that the event flow can include. The event-flow SDK provides interfaces that can be used to produce and consume CloudEvents with very little effort from the developer. For example, the following code will log the events it receives. The event-flow runtime is responsible for configuring the processor with the input/output connection details and any settings the developer requires.&lt;/p&gt; &lt;pre class="brush: jscript; title: ; notranslate"&gt; @CloudEventComponent public class EchoingProcessor { Logger logger = Logger.getLogger(DataLogger.class.getName()); @CloudEventProducer(name = &amp;#34;OUTPUT_DATA&amp;#34;) CloudEventProducerTarget target; @CloudEventConsumer(name = &amp;#34;INPUT_DATA&amp;#34;) public void onCloudEvent(CloudEvent evt){ if(evt.getData().isPresent()){ logger.info(evt.getData().get().toString()); } target.send(evt); } } &lt;/pre&gt; &lt;p&gt;The development of custom processors will be covered in depth in Part 3 of this series. Part 3 will also show how to develop processors in other languages.&lt;/p&gt; &lt;h3&gt;Design: EventFlow Manager API and UI&lt;/h3&gt; &lt;p&gt;Flows are represented internally as k8s Custom Resources. While these can be created via the standard k8s API and we provide Java classes for working with the CRD, this is not very convenient for most developers. To make it easier for developers to create and deploy flows, we have developed an initial web-based UI for creating flows graphically.&lt;/p&gt; &lt;p&gt;Using this tool, developers can select input topics that are already present in Red Hat AMQ Streams and connect them to processors that have been deployed into OpenShift. The Manager UI allows developers to set processor parameters and non-functional settings such as the number of replicas of each processor. It is likely that in the future the current prototype UI will be replaced with other tools that are more consistent and user-friendly.&lt;/p&gt; &lt;h3&gt;Deploy: Flow Operator&lt;/h3&gt; &lt;p&gt;The Flow Operator is deployed into OpenShift and is responsible for the deployment and configuration of Flows. The operator is notified when new Flow Custom Resources are deployed into the platform or when an existing one is updated. The Operator inspects the Flow CR (Custom Resource) and generates a set of resources (Deployments, ConfigMaps, and KafkaTopics) that can be deployed into OpenShift. In a new Flow deployment, these resources are created in the platform and the flow will begin to process data when it arrives on an input topic. In the case of reconfiguring an existing flow, the Operator will update only the components that have been changed, leaving the unchanged components &amp;#8220;as is.&amp;#8221; Such changes could be increasing the number of replicas of a processor or editing the flow definition to include additional processors.&lt;/p&gt; &lt;h3&gt;Connect: Making use of Red Hat AMQ Streams&lt;/h3&gt; &lt;p&gt;The EventFlow platform uses Red Hat AMQ Streams as the communication mechanism between microservices. This allows the platform to dynamically create topics as required and has some convenient properties with respect to deployment and reconfiguration.&lt;/p&gt; &lt;p&gt;The deployment of the flow processors may occur in any order dependant on factors such as whether any images are cached locally and the startup overhead for each container. Because Red Hat AMQ Streams will buffer the messages in between processors, we are able to instantiate the flow in any order with confidence that once upstream components have started, the messages will begin to flow.&lt;/p&gt; &lt;p&gt;Second, one of the properties of Apache Kafka that underlies Red Hat AMQ Streams is that it has the potential to store historical messages indefinitely. This feature means that if a new processor is added to a running flow, there is the potential to &amp;#8220;replay&amp;#8221; old messages through it and all downstream processors. This results in the reconfigured flow behaving as if it had been deployed initially.&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;Here are some additional Kafka posts that might be helpful:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/"&gt;Smart-Meter Data Processing Using Apache Kafka on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/31/introducing-the-kafka-cdi-library/"&gt;Introducing the Kafka-CDI Library&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/07/announcing-amq-streams-apache-kafka-on-openshift/"&gt;Announcing AMQ Streams: Apache Kafka on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This post presented a framework that is capable of processing streams of events using a set of components that are connected using an installation of Apache Kafka provided by the Red Hat AMQ Streams product. This approach to event processing allows developers to create simple components that can be wired together using either a graphical editor or via a flow definition document. This means that complex event-processing pipelines can be created relatively easily and then scaled in response to varying levels of demand or distributed over multiple cloud providers, as required.&lt;/p&gt; &lt;p&gt;The next posts in this series will describe the process of event-flow creation and deployment and also introduce the software development environment that enables developers to create their own processing components and link them together using this framework.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;title=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" data-a2a-url="https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/" data-a2a-title="EventFlow: Event-driven microservices on OpenShift (Part 1)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/"&gt;EventFlow: Event-driven microservices on OpenShift (Part 1)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gTleEq_ns84" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This post is the first in a series of three related posts that describes a lightweight cloud-native distributed microservices framework we have created called EventFlow. EventFlow can be used to develop streaming applications that can process CloudEvents, which are an effort to standardize upon a data format for exchanging information about events generated by cloud [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/"&gt;EventFlow: Event-driven microservices on OpenShift (Part 1)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">523017</post-id><dc:creator>Hugo Hiden</dc:creator><dc:date>2018-10-15T11:00:20Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/</feedburner:origLink></entry><entry><title>My first visit to Belarus speaking at the JFuture conference</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1JwjjP9KGsc/my-first-visit-to-belarus-speaking-at.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="speaker" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-my_first_visit_to_belarus_speaking_at_the_jfuture_conference</id><updated>2018-10-15T10:22:31Z</updated><published>2018-10-15T10:22:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;I just got back from Minsk, Belarus where I gave a workshop and a presentation at the &lt;a href="https://jfuture.by/"&gt;JFuture 2018&lt;/a&gt; conference.&lt;br /&gt;&lt;br /&gt;This was my first visit to Belarus, and its always good to see new parts of the world, and help spread the knowledge about our beloved integration software &lt;a href="http://camel.apache.org/"&gt;Apache Camel&lt;/a&gt;. I am traveling with Mr Camel so at the hotel we read the greeting card from the organisers.&lt;br /&gt;&lt;div&gt;&amp;nbsp;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-kroh2dos5n0/W8RmBG_zwyI/AAAAAAAABvE/CeLvwoIID7IGkivcrsLEemNBBS2P_5HBwCLcBGAs/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.35.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="347" data-original-width="515" height="215" src="https://1.bp.blogspot.com/-kroh2dos5n0/W8RmBG_zwyI/AAAAAAAABvE/CeLvwoIID7IGkivcrsLEemNBBS2P_5HBwCLcBGAs/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.35.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;On friday I hosted an Apache Camel microservices workshop with 10 Java developers whom were introduced to Apache Camel and then had fun hacking some Camel microservices code. The material is awesome and much credit to &lt;a href="https://github.com/nicolaferraro/camel-workshop"&gt;Nicola Ferraro&lt;/a&gt; for creating the workshop demo, which we joined presented earlier this year at JBCNConf in Barcelona.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-wy2HKSJcNoM/W8RmBV0UChI/AAAAAAAABvg/iMTglewKC3MwApe6VcG0cInHHttEi5hhgCEwYBhgL/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.25.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="344" data-original-width="513" height="214" src="https://4.bp.blogspot.com/-wy2HKSJcNoM/W8RmBV0UChI/AAAAAAAABvg/iMTglewKC3MwApe6VcG0cInHHttEi5hhgCEwYBhgL/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.25.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;After the workshop I went out for a run in the city, mostly in the lovely parks. The weather was beautify with sun and 15 degrees celcius. The parks are full of tree leaves as the season is autumn.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-Gig7CFJ0zu8/W8Rnb1T7l5I/AAAAAAAABvo/0SDAq65qCKgpHuhu5kZknQWPJePidoqVwCLcBGAs/s1600/minsik-run.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="500" data-original-width="661" height="242" src="https://3.bp.blogspot.com/-Gig7CFJ0zu8/W8Rnb1T7l5I/AAAAAAAABvo/0SDAq65qCKgpHuhu5kZknQWPJePidoqVwCLcBGAs/s320/minsik-run.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-Um0-ez5IhSY/W8RjsX89dWI/AAAAAAAABuk/jGHK9L-yYxwBB65LWZvV3onyFu9oQXvAgCEwYBhgL/s1600/IMG_7346.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://1.bp.blogspot.com/-Um0-ez5IhSY/W8RjsX89dWI/AAAAAAAABuk/jGHK9L-yYxwBB65LWZvV3onyFu9oQXvAgCEwYBhgL/s320/IMG_7346.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-KULIy6Pkaf8/W8Rjuc3kmrI/AAAAAAAABu4/xQlY0kaAnmsh5BZKukbl3gv9u9v3SFn5ACEwYBhgL/s1600/IMG_7350.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://1.bp.blogspot.com/-KULIy6Pkaf8/W8Rjuc3kmrI/AAAAAAAABu4/xQlY0kaAnmsh5BZKukbl3gv9u9v3SFn5ACEwYBhgL/s320/IMG_7350.JPG" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-Nl6lotHe3DY/W8RjuPBJ3wI/AAAAAAAABuk/LZ9EonYppYwnDNcNALfp3iSHsiWPTkiXQCEwYBhgL/s1600/IMG_7351.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://2.bp.blogspot.com/-Nl6lotHe3DY/W8RjuPBJ3wI/AAAAAAAABuk/LZ9EonYppYwnDNcNALfp3iSHsiWPTkiXQCEwYBhgL/s320/IMG_7351.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s1600/IMG_7358.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s320/IMG_7358.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-J3mXUyWGhKg/W8RjxOWrcCI/AAAAAAAABuo/k5YRpubLj6QngPdgdcNRR8mhTJFL9DjuACEwYBhgL/s1600/IMG_7363.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://3.bp.blogspot.com/-J3mXUyWGhKg/W8RjxOWrcCI/AAAAAAAABuo/k5YRpubLj6QngPdgdcNRR8mhTJFL9DjuACEwYBhgL/s320/IMG_7363.JPG" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-r0uvmz8lcvQ/W8RjyXvsOzI/AAAAAAAABu8/9O-0Xyg69awcGxj1T8IPLWkUBTHoTyOLgCEwYBhgL/s1600/IMG_7360.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://3.bp.blogspot.com/-r0uvmz8lcvQ/W8RjyXvsOzI/AAAAAAAABu8/9O-0Xyg69awcGxj1T8IPLWkUBTHoTyOLgCEwYBhgL/s320/IMG_7360.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-K0FOjC5ZUpI/W8Rj2YuaD0I/AAAAAAAABu8/8T-QR7ovL6QEnrZg6LxqG7xI6mSVcCOXwCEwYBhgL/s1600/IMG_7423.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://1.bp.blogspot.com/-K0FOjC5ZUpI/W8Rj2YuaD0I/AAAAAAAABu8/8T-QR7ovL6QEnrZg6LxqG7xI6mSVcCOXwCEwYBhgL/s1600/IMG_7423.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;On Saturday it was conference day, and the venue is the royal theatre in Minsk.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-ZOniGXF2Tzc/W8RjydAICiI/AAAAAAAABuw/3Nq5sbCpzjI9LJRA4FtjW0zHruriKXLrwCEwYBhgL/s1600/IMG_7375.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://4.bp.blogspot.com/-ZOniGXF2Tzc/W8RjydAICiI/AAAAAAAABuw/3Nq5sbCpzjI9LJRA4FtjW0zHruriKXLrwCEwYBhgL/s1600/IMG_7375.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-J8RBjWWRmPE/W8RjypEa1sI/AAAAAAAABu0/Z-5STGIO3QIrKoFizzZVnjLQHYOsL4yGQCEwYBhgL/s1600/IMG_7376.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://2.bp.blogspot.com/-J8RBjWWRmPE/W8RjypEa1sI/AAAAAAAABu0/Z-5STGIO3QIrKoFizzZVnjLQHYOsL4yGQCEwYBhgL/s1600/IMG_7376.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;After they keynote we had the 1st set of tracks, and I was honoured to do my performance on the main stage.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-l_P7Md_JGe0/W8RjzCUUTQI/AAAAAAAABuk/WelZ0uk4-asU_IHkDqEWKcPLAougMs9HgCEwYBhgL/s1600/IMG_7385.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="591" data-original-width="332" height="320" src="https://3.bp.blogspot.com/-l_P7Md_JGe0/W8RjzCUUTQI/AAAAAAAABuk/WelZ0uk4-asU_IHkDqEWKcPLAougMs9HgCEwYBhgL/s320/IMG_7385.jpg" width="179" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I was not the only red hatter, as Justin Lee, traveled all the way from New York to be here, and present about serverless.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-zm3JjYijlKQ/W8Rjy9fqfAI/AAAAAAAABu0/UYO2Sy0UVLYlpPxgvViF45_LE90eL7qFwCEwYBhgL/s1600/IMG_7384.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://4.bp.blogspot.com/-zm3JjYijlKQ/W8Rjy9fqfAI/AAAAAAAABu0/UYO2Sy0UVLYlpPxgvViF45_LE90eL7qFwCEwYBhgL/s1600/IMG_7384.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;For his presentation I got myself a seat in the balcony, which has a very nice view of the stage.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-BblaGxfnUzs/W8RmBU4nb8I/AAAAAAAABvc/h4f4kqsdhEQ3HK65qwLe115ClhcA9NCfwCEwYBhgL/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.58.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="263" data-original-width="515" height="163" src="https://4.bp.blogspot.com/-BblaGxfnUzs/W8RmBU4nb8I/AAAAAAAABvc/h4f4kqsdhEQ3HK65qwLe115ClhcA9NCfwCEwYBhgL/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.58.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I walked the city on the afternoon, and took some photos. After a couple of hours I found a nice place at the backside of the palace of the republic where I enjoyed a margarita, to celebrate my first visit here.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-iBpLVBTe_ts/W8RmB14KTkI/AAAAAAAABvY/WBYNiATSGIs4HBiVe0B7PuDntw3oESkBwCEwYBhgL/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.03.06.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="264" data-original-width="515" height="164" src="https://1.bp.blogspot.com/-iBpLVBTe_ts/W8RmB14KTkI/AAAAAAAABvY/WBYNiATSGIs4HBiVe0B7PuDntw3oESkBwCEwYBhgL/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.03.06.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-CyWAJQg6SrM/W8RjurzZuuI/AAAAAAAABuo/OCUuj9OMilIhnZpInlNAD_j9QnG5lKe3QCEwYBhgL/s1600/IMG_7354.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://2.bp.blogspot.com/-CyWAJQg6SrM/W8RjurzZuuI/AAAAAAAABuo/OCUuj9OMilIhnZpInlNAD_j9QnG5lKe3QCEwYBhgL/s320/IMG_7354.JPG" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s1600/IMG_7358.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s320/IMG_7358.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-E5zhLZGaS14/W8Rj06ShRdI/AAAAAAAABuw/KUXJoFhokG87CyfziPQofpt4BlEhrk6GwCEwYBhgL/s1600/IMG_7404.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://4.bp.blogspot.com/-E5zhLZGaS14/W8Rj06ShRdI/AAAAAAAABuw/KUXJoFhokG87CyfziPQofpt4BlEhrk6GwCEwYBhgL/s1600/IMG_7404.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I stayed at the Willing hotel which is located 20 minute walk from the city center. Its in an area with old factories that are now being put up for new use with startups and hipsters in the neighborhood. So there are many coffee shops and some bars. The big walls of these factories were painted by local and foreign artists.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-0ly9ZXc7Vyc/W8RjzfnoaKI/AAAAAAAABuo/bZvY20K_ORogKGJZzw2LO5CdoMue-izUACEwYBhgL/s1600/IMG_7387.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="192" data-original-width="256" src="https://2.bp.blogspot.com/-0ly9ZXc7Vyc/W8RjzfnoaKI/AAAAAAAABuo/bZvY20K_ORogKGJZzw2LO5CdoMue-izUACEwYBhgL/s1600/IMG_7387.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-VOXt9n4KSOk/W8RjzcfUWOI/AAAAAAAABu4/LQ-qxywFbR87t5vJK1rsFtWQ-EsOGZG5gCEwYBhgL/s1600/IMG_7390.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://2.bp.blogspot.com/-VOXt9n4KSOk/W8RjzcfUWOI/AAAAAAAABu4/LQ-qxywFbR87t5vJK1rsFtWQ-EsOGZG5gCEwYBhgL/s1600/IMG_7390.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-VCqgLTfUVek/W8RjzwcXFII/AAAAAAAABu0/QU424xUQU3ov8Bm97H-AgRTBHBxDVN1mACEwYBhgL/s1600/IMG_7396.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="192" data-original-width="256" src="https://3.bp.blogspot.com/-VCqgLTfUVek/W8RjzwcXFII/AAAAAAAABu0/QU424xUQU3ov8Bm97H-AgRTBHBxDVN1mACEwYBhgL/s1600/IMG_7396.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I enjoyed my time in Minsk, and I would like to say a warm thanks to the organisers for inviting me to come. I wish you the best with the conference and can recommend it to other speakers.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=VkEM0eLw8BU:vPVqAwI-xxY:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=VkEM0eLw8BU:vPVqAwI-xxY:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=VkEM0eLw8BU:vPVqAwI-xxY:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/VkEM0eLw8BU" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1JwjjP9KGsc" height="1" width="1" alt=""/&gt;</content><summary>I just got back from Minsk, Belarus where I gave a workshop and a presentation at the JFuture 2018 conference. This was my first visit to Belarus, and its always good to see new parts of the world, and help spread the knowledge about our beloved integration software Apache Camel. I am traveling with Mr Camel so at the hotel we read the greeting card from the organisers.   On friday I hosted an Apa...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2018-10-15T10:22:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/VkEM0eLw8BU/my-first-visit-to-belarus-speaking-at.html</feedburner:origLink></entry><entry><title>Launch of Business Applications</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FkBeYf4Z7NA/launch-of-business-applications.html" /><category term="business_applications" scheme="searchisko:content:tags" /><category term="case_applications" scheme="searchisko:content:tags" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><category term="get_started_jbpm" scheme="searchisko:content:tags" /><category term="jbpm_applications" scheme="searchisko:content:tags" /><category term="jbpm_guide" scheme="searchisko:content:tags" /><category term="start.jbpm.org" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-launch_of_business_applications</id><updated>2018-10-15T08:55:22Z</updated><published>2018-10-15T08:55:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;h2 style="text-align: center;"&gt;The time has come - Business Applications are here!!!&lt;/h2&gt;&lt;div style="text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: center;"&gt;It's a great pleasure to announce that the Business Applications are now officially launched and ready for you to get started.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-biy16tKbncA/W8RRPKk1ycI/AAAAAAAABhY/TVsY6ItbmxspsPf4fXb-SfvgZxaUFuDMACLcBGAs/s1600/start-jbpm-org.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="497" data-original-width="877" height="361" src="https://1.bp.blogspot.com/-biy16tKbncA/W8RRPKk1ycI/AAAAAAAABhY/TVsY6ItbmxspsPf4fXb-SfvgZxaUFuDMACLcBGAs/s640/start-jbpm-org.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;a href="http://start.jbpm.org/"&gt;start.jbpm.org&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Business application&lt;/b&gt; can be defined as an automated solution, built with selected frameworks and capabilities that implements business functions and/or business problems. Capabilities can be (among others):&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;persistence&lt;/li&gt;&lt;li&gt;messaging&lt;/li&gt;&lt;li&gt;transactions&lt;/li&gt;&lt;li&gt;business processes,&amp;nbsp;&lt;/li&gt;&lt;li&gt;business rules&lt;/li&gt;&lt;li&gt;planning solutions&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;Capabilities essentially define the features that your business application will be equipped with. Available options are:&lt;/div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;b&gt;Business automation&lt;/b&gt; covers features for process management, case management, decision management and optimisation. These will be by default configured in the service project of your business application. Although you can turn them off via configuration.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Decision management&lt;/b&gt; covers mainly decision and rules related features (backed by Drools project)&lt;/li&gt;&lt;li&gt;&lt;b&gt;Business optimisation&lt;/b&gt; covers planning problems and solutions related features (backed by OptaPlanner project)&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;div class="paragraph"&gt;Business application is more of a logical grouping of individual services that represent certain business capabilities. Usually they are deployed separately and can also be versioned individually. Overall goal is that the complete business application will allow particular domain to achieve their business goals e.g. order management, accommodation management, etc.&lt;br /&gt;&lt;br /&gt;Business application consists of various project types&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;b&gt;data model&lt;/b&gt; - basic maven/jar project to keep the data structures&lt;/li&gt;&lt;li&gt;&lt;b&gt;business assets&lt;/b&gt; - kjar project that can be easily imported into workbench for development&lt;/li&gt;&lt;li&gt;&lt;b&gt;service&lt;/b&gt; - service project that will include chosen capabilities with all bits configured&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;Read more about business applications &lt;a href="https://docs.jboss.org/jbpm/release/7.12.0.Final/jbpm-docs/html_single/index.html#_overview_2"&gt;here&lt;/a&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: center;"&gt;Get started now!&lt;/h2&gt;&lt;div&gt;To get started with your first business application, just go to &lt;a href="http://start.jbpm.org/"&gt;start.jbpm.org&lt;/a&gt; and generate your business application. This will provide you with a zip file that will consists of (selected) projects ready to run.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once you have the application up and running have a look at documentation that provides detailed description about business applications and various options in terms of configuration and development.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Make sure to not miss the tutorials that are included in the official documentation... these are being constantly updated so more and more guides are on the way. Each release will introduce at least 2 new tutorials ... so stay tuned.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: center;"&gt;Samples and more&lt;/h2&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-pwbl5zmVIbo/W8RSJTuw5BI/AAAAAAAABhg/cGzA7KUX3bgHeCI-kq99-Hm5wsXvQTJcACLcBGAs/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B10.36.14.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="857" data-original-width="1073" height="510" src="https://4.bp.blogspot.com/-pwbl5zmVIbo/W8RSJTuw5BI/AAAAAAAABhg/cGzA7KUX3bgHeCI-kq99-Hm5wsXvQTJcACLcBGAs/s640/Screen%2BShot%2B2018-10-15%2Bat%2B10.36.14.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;a href="https://github.com/business-applications"&gt;business-applications samples&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;Business application launch cannot be done without quite few examples that can give you some ideas on how to get going, to name just few (and again more are coming)&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Driver pickup with IFTTT&amp;nbsp;&lt;/li&gt;&lt;li&gt;Dashboard app with Thymeleaf&lt;/li&gt;&lt;li&gt;IT Orders with tracking service built with Vert.x&lt;/li&gt;&lt;li&gt;Riot League of Legends&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;This &lt;a href="https://github.com/business-applications"&gt;business application GitHub organisation&lt;/a&gt; includes also source code for tutorials so make sure you visit it (and stay around for a bit as more will come).&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: center;"&gt;Call for contribution and feedback&lt;/h2&gt;&lt;div&gt;Last but not least, we would like to call out for contribution and feedback. Please give this approach a go and let us know what you think, what we could improve or share the ideas for business application you might have.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Reach out to us&amp;nbsp;&lt;a href="https://jbpm.org/community/getHelp.html"&gt;via standard channels&lt;/a&gt; such as mailing lists or IRC channel.&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FkBeYf4Z7NA" height="1" width="1" alt=""/&gt;</content><summary>The time has come - Business Applications are here!!! It's a great pleasure to announce that the Business Applications are now officially launched and ready for you to get started. start.jbpm.org Business application can be defined as an automated solution, built with selected frameworks and capabilities that implements business functions and/or business problems. Capabilities can be (among others...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-10-15T08:55:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/10/launch-of-business-applications.html</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 20/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/YvbAF6bWDNU/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_20_2018</id><updated>2018-10-15T08:16:11Z</updated><published>2018-10-15T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="books"&gt;&lt;a class="anchor" href="#books"&gt;&lt;/a&gt;Books&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This &lt;a href="https://dzone.com/articles/5-books-to-learn-hibernate-for-java-developers"&gt;DZone article&lt;/a&gt; shows you the best 5 books to learn Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In &lt;a href="https://medium.com/@jerolba/persisting-fast-in-database-1af4a281e3a"&gt;this article&lt;/a&gt;, Jerónimo López explains several optimizations that you do to speed up batch processing tasks when using JPA and Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When it comes to reading data, you should always fetch just as much data that you need to fulfill a given business requirement. Fetching more data than necessary is the most common problem that leads to application performance issues. For this reason, JPA and Hibernate provide &lt;a href="https://vladmihalcea.com/query-pagination-jpa-hibernate/"&gt;a very flexible query pagination mechanism&lt;/a&gt; that works for both entity queries (JPQL and Criteria API) and native SQL queries.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Using DTO projections is a very efficient way of fetching read-only data. If you are using Spring Data JPA, &lt;a href="https://www.bluemagma.be/2018/10/content-negotiation-with-spring-data-jpa-projections/"&gt;this article&lt;/a&gt; explains how to use content negotiation for specifying the DTO type.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For our Portuguese readers, &lt;a href="http://db4beginners.com/blog/db-relacional-transacao/"&gt;this article&lt;/a&gt; explains what database transactions are and why you need them to ensure data integrity.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In &lt;a href="https://www.theserverside.com/tip/How-JPA-and-Hibernate-simplify-data-persistence"&gt;this article&lt;/a&gt;, you are going to find how you can simplify data persistence with JPA and Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Eugen Paraschiv wrote &lt;a href="https://www.baeldung.com/hibernate-proxy-load-method"&gt;an article&lt;/a&gt; about Hibernate proxies and how the &lt;code&gt;Session&lt;/code&gt; &lt;code&gt;load&lt;/code&gt; method works in comparison to the &lt;code&gt;get&lt;/code&gt; or &lt;code&gt;find&lt;/code&gt; methods.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52680020/hibernate-not-able-to-register-limit-function-of-mysql-in-custom-dialect/52701546#52701546"&gt;Hibernate not able to register 'LIMIT' function of MySQL in custom dialect&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/should-i-use-an-application-generated-entity-identifier-or-use-the-database-native-generator-with-hibernate/1493"&gt;Should I use an application-generated entity identifier or use the database native generator with Hibernate?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/19649194/hibernate-pagination-mechanism"&gt;Hibernate pagination mechanism&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/16088949/jpa-query-to-select-based-on-criteria-alongwith-pagination/52724851#52724851"&gt;How to paginate a JPA Query&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/42173894/hibernate-enablefilter-not-working-when-loading-entity-by-id/42197922#42197922"&gt;Hibernate enableFilter not working when loading entity by id&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/15974474/mapping-postgresql-json-column-to-hibernate-value-type/37946530#37946530"&gt;Mapping PostgreSQL JSON column to Hibernate value type&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/24877814/unidirectional-onetomany-fails-equality-test-in-jpa-2-1/24879391#24879391"&gt;Unidirectional @OneToMany association fails equality test in JPA&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/29869934/unit-testing-after-adding-database-with-hibernate/29877389#29877389"&gt;Unit testing after adding the database schema with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/24901118/transactionmanager-for-multiple-databases/24901564#24901564"&gt;TransactionManager for multiple databases&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/30576385/how-to-log-the-start-and-the-completion-of-db-transactions-in-hibernate/30589533#30589533"&gt;How to log the start and the completion of DB transactions in Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52678532/update-timestamp-for-each-row-in-hibernate/52732874#52732874"&gt;Update timestamp for each row in Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/29762653/why-does-hibernate-generate-a-cross-join-for-an-implicit-join-of-a-manytoone-as/29764340#29764340"&gt;Why does Hibernate generate a CROSS JOIN for an implicit join of a @ManyToOne association?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-to-access-entity-properties-through-non-standard-getters-and-setters-with-hibernate/1513"&gt;How to access entity properties through non-standard getters and setters with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/jpa-many-to-many-association-with-extra-columns-not-working-with-hibernate/1517"&gt;JPA many-to-many association with extra columns not working with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-5-3-sql-server-varchar-max-text-displayed-as-chinese-characters/1524/2"&gt;Hibernate 5.3, SQL Server varchar(max) text displayed as Chinese characters&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/YvbAF6bWDNU" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Books This DZone article shows you the best 5 books to learn Hibernate. Articles In this article, Jerónimo López explains several optimizations that you do to speed up batch processing tasks when using JPA and Hibernate. When it comes to reading ...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-10-15T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/10/15/hibernate-community-newsletter-2018-20/</feedburner:origLink></entry><entry><title>Introducing Camel K</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nHh3RLV1rOg/" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_nicolaferraro" scheme="searchisko:content:tags" /><category term="JBoss Fuse" scheme="searchisko:content:tags" /><category term="Knative" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><author><name>Nicola Ferraro</name></author><id>searchisko:content:id:jbossorg_blog-introducing_camel_k</id><updated>2018-10-15T13:00:00Z</updated><published>2018-10-14T22:00:00Z</published><content type="html">&lt;p&gt;Just few months ago, we were discussing about a new project that we could start as part of Apache Camel. A project with the potential to change the way people deal with integration. That project is now here and it’s called &lt;strong&gt;“Apache Camel K”&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The “K” in the title is an obvious reference to &lt;a href="https://kubernetes.io/"&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/a&gt;, you may think. But there’s also a less-obvious reference to &lt;a href="https://cloud.google.com/knative/"&gt;&lt;strong&gt;Knative&lt;/strong&gt;&lt;/a&gt;: a community project with the target of creating a common set of building blocks for &lt;strong&gt;serverless&lt;/strong&gt; applications. Yes, going “serverless” is the base idea that inspired many architectural decisions for Camel K.&lt;/p&gt; &lt;p&gt;But, let’s take this one step at time…&lt;/p&gt; &lt;h2 id="what-is-camel-k"&gt;What is “Camel K”?&lt;/h2&gt; &lt;p&gt;Apache Camel K is a lightweight cloud integration platform based on the Apache Camel framework. It &lt;strong&gt;runs natively on Kubernetes and Openshift&lt;/strong&gt; and it’s specifically designed for &lt;strong&gt;serverless and microservice architectures&lt;/strong&gt;. When I say “it runs”, I mean “it runs, now, you can try it!”. Just visit the homepage of the project on Github and follow the instructions: &lt;a href="https://github.com/apache/camel-k"&gt;&lt;strong&gt;https://github.com/apache/camel-k&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;It’s based on the “operator pattern” and leverages the &lt;a href="https://github.com/operator-framework/operator-sdk"&gt;Operator SDK&lt;/a&gt; to perform operations on Kubernetes resources (we define some &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources&lt;/a&gt; beside the standard ones). The operator is written in &lt;a href="https://golang.org/"&gt;Go&lt;/a&gt; while the runtime is JVM based and leverages &lt;strong&gt;all the 200+ components&lt;/strong&gt; already available in Apache Camel.&lt;/p&gt; &lt;p&gt;Like Kubernetes and OpenShift, also &lt;strong&gt;Knative&lt;/strong&gt; will be a target platform in the near future. Specifically, we’re following the development of &lt;a href="https://github.com/knative/eventing"&gt;Knative Eventing&lt;/a&gt; and &lt;a href="https://github.com/knative/serving"&gt;Knative Serving&lt;/a&gt; building blocks to provide a full support for them, once they reach an adequate level of maturity.&lt;/p&gt; &lt;p&gt;Camel K brings integration to the next level, but at the same time is a return back to the roots for the Camel project: the &lt;a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/"&gt;&lt;strong&gt;Enterprise Integration Patterns (EIP)&lt;/strong&gt;&lt;/a&gt;. Camel has been shaped around enterprise integration patterns since its inception and developers have created a DSL that often maps patterns in a 1:1 relationship.&lt;/p&gt; &lt;p&gt;I’m not exaggerating if I state that now: &lt;strong&gt;the Camel DSL is the language of EIP&lt;/strong&gt;. It’s (at least in my opinion) the language that expresses better most of the patterns that were present in the original &lt;a href="https://www.enterpriseintegrationpatterns.com/index.html"&gt;“book of integration”&lt;/a&gt;, but also other patterns that have been added by the community during all these years. And the community keeps adding patterns and new components in every release.&lt;/p&gt; &lt;p&gt;The idea of Camel K is simply stated: &lt;strong&gt;let people use those Enterprise Integration Patterns natively on Kubernetes&lt;/strong&gt;, expressing them using the &lt;strong&gt;poweful Camel DSL&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;If I should provide a &lt;strong&gt;architectural overview&lt;/strong&gt; on Camel K, I’d draw the following diagrams:&lt;/p&gt; &lt;p style="text-align: center"&gt; &lt;img src="/images/post-camel-k-architecture.png" alt="Deployment Models for Camel K" /&gt; &lt;/p&gt; &lt;p&gt;Camel K is what you get if you take the &lt;strong&gt;integration DSL distilled&lt;/strong&gt; from the rest of the framework and offer a way to write integration code that is executed directly on a cloud platform: it may be a &lt;strong&gt;“modern” cloud&lt;/strong&gt; platform like Kubernetes or Openshift, or a &lt;strong&gt;“futuristic” cloud&lt;/strong&gt; platform like Knative for serverless workloads (Knative can run on both OpenShift and Kubernetes and it’s powered by &lt;a href="https://istio.io/"&gt;Istio&lt;/a&gt;).&lt;/p&gt; &lt;h2 id="how-does-it-work"&gt;How does it work?&lt;/h2&gt; &lt;p&gt;Speaking technically, the starting point is writing the integration code that we want to run. For example:&lt;/p&gt; &lt;p&gt;File: &lt;em&gt;integrate.groovy&lt;/em&gt;&lt;/p&gt; &lt;div class="language-groovy highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="c1"&gt;// expose a rest endpoint that routes messages to a Kafka topic&lt;/span&gt; &lt;span class="n"&gt;rest&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;post&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"/resources"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;route&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;to&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"kafka:messages"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// transform all messages and publish them on a HTTP endpoint&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"kafka:messages"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;()...&lt;/span&gt; &lt;span class="c1"&gt;// any kind of transformation&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;to&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"http://myendpoint/messages"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Integrations can range from simple &lt;a href="https://github.com/apache/camel-k/blob/35aa1b3d39508ea901be7a7a1c5f4d256ce0eabb/runtime/examples/routes.js#L29"&gt;timer-to-log&lt;/a&gt; dummy examples to complex processing workflows connecting several external systems, but you write them using the same Camel DSL.&lt;/p&gt; &lt;p&gt;Actually, I talked about “a” Camel DSL, but many of you already know that the Camel DSL is not a proper standalone language, but a set of primitives that can be used in &lt;strong&gt;multiple programming languages&lt;/strong&gt;. So far we support the following languages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Groovy&lt;/strong&gt;: it is probably the best language for scripting and it is currently the preferred language for writing Camel K integration code&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Kotlin&lt;/strong&gt;: yes, we support also Kotlin that offers a similar experience to Groovy&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Java&lt;/strong&gt;: it’s the classic Camel DSL that many of you already know&lt;/li&gt; &lt;li&gt;&lt;strong&gt;XML&lt;/strong&gt;: it’s also a classic DSL adaptation and give its best when you plan to use one of the visual editing tools that already exist&lt;/li&gt; &lt;li&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: yes, we support it as well!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let’s not complicate things too much and consider one of the simplest integration for the moment. The classic &lt;strong&gt;“Camel Hello World”&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;File: &lt;em&gt;hello.groovy&lt;/em&gt;&lt;/p&gt; &lt;div class="language-groovy highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"timer:tick?period=3s"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBody&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;constant&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello World from Camel K!!!"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;to&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"log:message"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;A user that wants to run this integration on a cloud platform needs to download a small binary file that is available in the &lt;a href="https://github.com/apache/camel-k/releases"&gt;release page on the Camel K Github repository&lt;/a&gt;. It’s called &lt;strong&gt;kamel&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The &lt;strong&gt;kamel&lt;/strong&gt; binary contains also a command to prepare your Kubernetes cluster for running integrations. Just run:&lt;/p&gt; &lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;kamel install &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Will take care of installing the Camel K CRDs, setting up privileges and create the operator (see next) in the current namespace.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; in some cluster configurations, you need to be a cluster admin to install a CRD (it’s a operation that should be done only once for the entire cluster). The &lt;code class="highlighter-rouge"&gt;kamel&lt;/code&gt; binary will help you troubleshoot. If you want to work on a development cluster like &lt;em&gt;Minishift&lt;/em&gt; or &lt;em&gt;Minikube&lt;/em&gt;, you can easily follow the &lt;a href="https://github.com/apache/camel-k/blob/master/docs/cluster-setup.adoc"&gt;dev cluster setup guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once the cluster is prepared and the operator installed in the current namespace:&lt;/p&gt; &lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;kamel run hello.groovy &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;And your done!&lt;/p&gt; &lt;p&gt;This is what happens under the hood:&lt;/p&gt; &lt;p style="text-align: center"&gt; &lt;img src="/images/post-camel-k-architecture-detail.png" alt="Camel K Architecture Details" /&gt; &lt;/p&gt; &lt;p&gt;The &lt;strong&gt;kamel&lt;/strong&gt; tool will sync your code with a Kubernetes custom resource of Kind &lt;strong&gt;Integration&lt;/strong&gt; named &lt;strong&gt;hello&lt;/strong&gt; (after the file name) in the current namespace.&lt;/p&gt; &lt;p&gt;The &lt;strong&gt;Camel K Operator&lt;/strong&gt; is the component that makes all this possible by configuring all Kubernetes resources needed for running your integration. I’ll talk more about it later.&lt;/p&gt; &lt;p&gt;There exists also a &lt;strong&gt;dev mode&lt;/strong&gt; that allow users to create integration incrementally and with &lt;strong&gt;immediate “buildless” redeploys&lt;/strong&gt;. I think a demo is worth 1000 words.&lt;/p&gt; &lt;h2 id="demo"&gt;Demo&lt;/h2&gt; &lt;p&gt;The following video shows an example of what you can do with Camel K. It starts &lt;strong&gt;from the installation&lt;/strong&gt; on a Minishift dev cluster, showing how to run a basic quickstart. Then it proceeds with a &lt;strong&gt;more complex example&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The second integration shown in the video will connect a &lt;strong&gt;Telegram&lt;/strong&gt; bot (you can interact with it through the Telegram app on your mobile phone) to a &lt;strong&gt;Kafka&lt;/strong&gt; topic that will be used to buffer messages and to throttle them. Messages will be received from Kafka again, filtered through one of the basic &lt;strong&gt;enterprise integration patterns&lt;/strong&gt; available out-of-the box in Apache Camel, then &lt;strong&gt;forwarded to a external HTTPS&lt;/strong&gt; endpoint.&lt;/p&gt; &lt;p&gt;All this is done in few minutes of video, and all integrations are created &lt;strong&gt;incrementally&lt;/strong&gt;, leveraging the new build engine behind Camel K that requires &lt;strong&gt;just 1 second to redeploy&lt;/strong&gt; the integration after each change.&lt;/p&gt; &lt;p&gt;Take a look:&lt;/p&gt; &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/9Y5JfYiiBwM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""&gt;&lt;/iframe&gt; &lt;h2 id="bringing-operators-to-the-next-level"&gt;Bringing “operators” to the next level&lt;/h2&gt; &lt;p&gt;&lt;a href="https://github.com/operator-framework/operator-sdk"&gt;Operator SDK&lt;/a&gt; is the framework that makes it possible to create all Kubernetes resources needed for running the “Camel DSL script”.&lt;/p&gt; &lt;p&gt;Operators are commonly used to install and configure applications or platforms on Kubernetes and Openshift. They are the digital version of the “human operator” that once installed the application in legacy environments, making sure that everything is in place for the application to run.&lt;/p&gt; &lt;p&gt;We brought this concept to the &lt;strong&gt;next level&lt;/strong&gt; in Camel K. The operator is &lt;strong&gt;“intelligent”&lt;/strong&gt; and knows what you want to run. It &lt;strong&gt;can understand the Camel DSL&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;So, &lt;strong&gt;for example&lt;/strong&gt;, if you define a REST endpoint using the Camel REST DSL, the operator will make sure that your integration is exposed to the outside and it will create a Service and a Route on OpenShift to expose it, or a Ingress on vanilla Kubernetes.&lt;/p&gt; &lt;p&gt;And in the future, it will have more administrative responsibilities:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It will expose webhooks on Kubernetes and activate the webhook registration with the external provider to receive data&lt;/li&gt; &lt;li&gt;It will subscribe to feeds that you need to manage in your integration&lt;/li&gt; &lt;li&gt;It will convert your “polling” routes into Kubernetes Cronjobs for optimizing resource utilization&lt;/li&gt; &lt;li&gt;It will use a optimized Camel runtime platform under the hood if your routes support it&lt;/li&gt; &lt;li&gt;It will… do a lot of useful things!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The operator will make sure that all you should do is writing your integration in a “Camel DSL Script”, without caring about any administrative operation. That’s what we mean with &lt;strong&gt;“intelligent operator”&lt;/strong&gt;.&lt;/p&gt; &lt;h2 id="whats-next"&gt;What’s next&lt;/h2&gt; &lt;p&gt;There are a lot of things coming. We keep updated the &lt;a href="https://github.com/apache/camel-k/projects"&gt;projects section&lt;/a&gt; in the github repository with the current areas we’re working on. Those include the already mentioned work on &lt;strong&gt;Knative&lt;/strong&gt; and also a &lt;strong&gt;Web UI&lt;/strong&gt; for Camel K that will really rock!&lt;/p&gt; &lt;p&gt;We love contributions! If you’re interested in the project, there are a lot of ways to contribute.&lt;/p&gt; &lt;p&gt;Meet us in our &lt;a href="https://gitter.im/apache/camel-k?utm_source=share-link&amp;amp;utm_medium=link&amp;amp;utm_campaign=share-link"&gt;dedicated Gitter room&lt;/a&gt; for more information.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nHh3RLV1rOg" height="1" width="1" alt=""/&gt;</content><summary>Just few months ago, we were discussing about a new project that we could start as part of Apache Camel. A project with the potential to change the way people deal with integration. That project is now here and it’s called “Apache Camel K”. The “K” in the title is an obvious reference to Kubernetes, you may think. But there’s also a less-obvious reference to Knative: a community project with the t...</summary><dc:creator>Nicola Ferraro</dc:creator><dc:date>2018-10-14T22:00:00Z</dc:date><feedburner:origLink>https://www.nicolaferraro.me/2018/10/15/introducing-camel-k/</feedburner:origLink></entry><entry><title>jBPM Business Applications + IFTTT = Control everything!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/bctasJtzw1M/jbpm-business-applications-ifttt.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Tihomir Surdilovic</name></author><id>searchisko:content:id:jbossorg_blog-jbpm_business_applications_ifttt_control_everything</id><updated>2018-10-12T22:58:11Z</updated><published>2018-10-12T22:58:00Z</published><content type="html">Here is another &lt;a href="http://start.jbpm.org/"&gt;jBPM Business Application&lt;/a&gt;&amp;nbsp;demo which uses the &lt;a href="https://platform.ifttt.com/"&gt;IFTTT&lt;/a&gt; workitem handler to connect your business processes in your business applications with the IFTTT Service.&lt;br /&gt;&lt;br /&gt;In this demo we present users with a simple form where they can enter in their info and the location where they are in order for someone to come pick them up:&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/--bkOjk0Otvo/W8EhbeTGv8I/AAAAAAAAha8/fInTyHyNKQMBc-Nuoqd2phIyM1qisgFKACLcBGAs/s1600/Screen%2BShot%2B2018-10-12%2Bat%2B6.42.59%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="589" data-original-width="1600" height="146" src="https://3.bp.blogspot.com/--bkOjk0Otvo/W8EhbeTGv8I/AAAAAAAAha8/fInTyHyNKQMBc-Nuoqd2phIyM1qisgFKACLcBGAs/s400/Screen%2BShot%2B2018-10-12%2Bat%2B6.42.59%2BPM.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Once the form is submitted our business process is started which passes this information to the IFTTT workitem handler that then calls an Applet on the IFTTT platform:&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-uHQgqUQqUUk/W8Ehu1KF1MI/AAAAAAAAhbE/alC0OSBdXlgvDzotnW3d7lzBZCFHyAGwgCLcBGAs/s1600/Screen%2BShot%2B2018-10-12%2Bat%2B6.47.51%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1408" data-original-width="840" height="200" src="https://1.bp.blogspot.com/-uHQgqUQqUUk/W8Ehu1KF1MI/AAAAAAAAhbE/alC0OSBdXlgvDzotnW3d7lzBZCFHyAGwgCLcBGAs/s200/Screen%2BShot%2B2018-10-12%2Bat%2B6.47.51%2BPM.png" width="118" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;This applet takes in the address entered by our user and &lt;b&gt;launches Google Maps on our phone showing us the directions where the user is and also sends us an SMS message&lt;/b&gt; showing this information as well.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-0P5erIpEnxM/W8ElpYIL-ZI/AAAAAAAAhbQ/Ap6kKP_q6cccy-jJTuOGR6bbn5VY7ZLDgCLcBGAs/s1600/Screen%2BShot%2B2018-10-12%2Bat%2B7.04.32%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="988" data-original-width="782" height="200" src="https://1.bp.blogspot.com/-0P5erIpEnxM/W8ElpYIL-ZI/AAAAAAAAhbQ/Ap6kKP_q6cccy-jJTuOGR6bbn5VY7ZLDgCLcBGAs/s200/Screen%2BShot%2B2018-10-12%2Bat%2B7.04.32%2BPM.png" width="158" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;The demo also shows how we can &lt;b&gt;start a business process in your business application in HTML&lt;/b&gt; via the &lt;a href="https://github.com/tsurdilo/thymeleaf-kie-server-dialect"&gt;kie-server thymeleaf dialect.&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;The source code of the demo can be &lt;a href="https://github.com/business-applications/sample-ifttt"&gt;downloaded here&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Here is also a video with a walkthrough of this demo. Watch the whole video or skip to the end to see the demo actually working ;)&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;iframe width="320" height="266" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/0bEEsm9spqg/0.jpg" src="https://www.youtube.com/embed/0bEEsm9spqg?feature=player_embedded" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;With the jBPM IFTTT Workitem you can do some really powerful things, connect your business processes with different devices for example. Hope this demo gives you some ideas on creating your own cool apps with &lt;a href="http://start.jbpm.org/"&gt;jBPM Business Applications&lt;/a&gt;.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/bctasJtzw1M" height="1" width="1" alt=""/&gt;</content><summary>Here is another jBPM Business Application demo which uses the IFTTT workitem handler to connect your business processes in your business applications with the IFTTT Service. In this demo we present users with a simple form where they can enter in their info and the location where they are in order for someone to come pick them up: Once the form is submitted our business process is started which pa...</summary><dc:creator>Tihomir Surdilovic</dc:creator><dc:date>2018-10-12T22:58:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/10/jbpm-business-applications-ifttt.html</feedburner:origLink></entry><entry><title>Securing .NET Core on OpenShift using HTTPS</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/4eWG9sB2j6Y/" /><category term=".NET Core" /><category term="Red Hat OpenShift Container Platform" /><category term="Security" /><category term="HTTPS" /><category term="Red Hat OpenShift" /><category term="SSL" /><category term="TLS" /><author><name>Tom Deseyn</name></author><id>https://developers.redhat.com/blog/?p=517327</id><updated>2018-10-12T11:00:11Z</updated><published>2018-10-12T11:00:11Z</published><content type="html">&lt;p&gt;In an effort to improve &lt;a href="https://developers.redhat.com/topics/secure-coding/"&gt;security&lt;/a&gt;, browsers have become stricter in warning users about sites that aren&amp;#8217;t properly secured with SSL/TLS. &lt;a href="https://developers.redhat.com/blog/category/dot-net/"&gt;ASP.NET Core&lt;/a&gt; 2.1 has improved support for HTTPS. You can read more about these enhancements in &lt;a href="https://blogs.msdn.microsoft.com/webdev/2018/02/27/asp-net-core-2-1-https-improvements/"&gt;Improvements to using HTTPS&lt;/a&gt;. In this blog post, we’ll look at how you can add HTTPS to your ASP.NET Core applications deployed on &lt;a href="https://www.openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Before we get down to business, let’s recap some OpenShift vocabulary and HTTPS fundamentals. If you are familiar, you can skip over these sections.&lt;/p&gt; &lt;h2&gt;OpenShift, pods, services, routes, and S2I&lt;/h2&gt; &lt;p&gt;&lt;a href="http://openshift.com/"&gt;OpenShift&lt;/a&gt; is a &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;-based open-source &lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;container&lt;/a&gt; application platform. A Kubernetes &lt;em&gt;pod&lt;/em&gt; is a set of containers that must be deployed on the same host. In most cases, a pod consists of a single container. When we run the same application in several pods, a &lt;em&gt;service&lt;/em&gt; does the load balancing across those pods. A &lt;em&gt;route&lt;/em&gt; makes a service accessible externally via a hostname.&lt;span id="more-517327"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;Source-to-Image (S2I)&lt;/em&gt; is a tool that allows OpenShift to build applications from source code into images. These images contain the applications that get executed in the pods.&lt;/p&gt; &lt;h2&gt;HTTPS, certificates, private keys, and certificate authorities&lt;/h2&gt; &lt;p&gt;When you browse to &lt;a href="https://www.redhat.com"&gt;redhat.com&lt;/a&gt;, the web server sends you a &lt;em&gt;certificate&lt;/em&gt;. This certificate links the name &lt;code&gt;www.redhat.com&lt;/code&gt; to a &lt;em&gt;public key&lt;/em&gt;. The certificate is signed by a &lt;em&gt;certificate authority&lt;/em&gt; (for example, DigiCert Inc). Since your browser trusts DigiCert, it trusts information in the certificate. The browser uses the public key to encrypt and decrypt information and the web server uses the corresponding &lt;em&gt;private key&lt;/em&gt;.&lt;/p&gt; &lt;h2&gt;Use-cases&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ll look at two use-cases: securing public communication and securing internal communication.&lt;/p&gt; &lt;p&gt;When we are securing &lt;em&gt;public&lt;/em&gt; communication, we want to add HTTPS to a route. After registering the hostname with a domain name registrar, we obtain a certificate from a certificate authority so we can prove we own that name.&lt;/p&gt; &lt;p&gt;Securing &lt;em&gt;internal&lt;/em&gt; communication means we want to use HTTPS to access services. HTTPS is not required between services when OpenShift is deployed on a private network and configured to restrict traffic between pods (using network policy/multitenant configuration). Even when it is not needed, you can use it to have an additional layer of security.&lt;/p&gt; &lt;h2&gt;Securing public communication&lt;/h2&gt; &lt;p&gt;OpenShift can terminate the HTTPS traffic and send plain HTTP requests to our container. To do this, we configure the OpenShift route to our service. As part of the configuration, we can provide the hostname, the certificate, and the private key. This can be done in the OpenShift Console: click the &lt;strong&gt;Edit this route&lt;/strong&gt; link under &lt;strong&gt;TLS Settings&lt;/strong&gt; and then select the &lt;strong&gt;Secure route &lt;/strong&gt;checkbox.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image4.png"&gt;&lt;img class=" aligncenter wp-image-517377 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image4.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image4-300x205.png" alt="Configuration for terminating HTTPS traffic " width="300" height="205" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image4-300x205.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image4.png 693w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;By changing &lt;strong&gt;Insecure Traffic&lt;/strong&gt; from &lt;code&gt;None&lt;/code&gt; to &lt;code&gt;Redirect&lt;/code&gt;, OpenShift will redirect (HTTP 302 response) clients from HTTP to HTTPS.&lt;/p&gt; &lt;p&gt;If we don’t provide a certificate, OpenShift will use a wildcard certificate for the subdomain of the router.&lt;/p&gt; &lt;h2&gt;Securing internal communication&lt;/h2&gt; &lt;p&gt;To secure internal communication, we need certificates for our services. Managing these certificates ourselves would be quite a challenge: generating certificates, handling expiration, distributing certificates, securing the private keys, and so on. Fortunately, OpenShift can take care of that.&lt;/p&gt; &lt;p&gt;To our application’s service, we add a &lt;code&gt;service.alpha.openshift.io/serving-cert-secret-name&lt;/code&gt; annotation. As a value, we pick a name for a secret. OpenShift will create this secret and generate a certificate and key that matches the internal service DNS name (&lt;code&gt;&amp;#60;service name&amp;#62;.&amp;#60;service.namespace&amp;#62;.svc&lt;/code&gt;). The certificate/key pair is automatically replaced when it gets close to expiration. We need to mount this secret in our ASP.NET Core container and tell the web server to use it.&lt;/p&gt; &lt;p&gt;When someone is using our service (for example, another .NET Core service deployed on OpenShift) they can now reach it over HTTPS. However, the certificate generated by OpenShift uses an internal certificate authority. For applications to trust that certificate authority, OpenShift provides a certificate bundle at &lt;code&gt;/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;After importing that certificate authority bundle, applications can securely access the services via &lt;code&gt;https://&amp;#60;service name&amp;#62;&lt;/code&gt;.&lt;code&gt;&amp;#60;service.namespace&amp;#62;.svc:8080&lt;/code&gt;. We can trust the bundle in our container using &lt;code&gt;DOTNET_SSL_DIRS&lt;/code&gt;. The &lt;a href="https://blogs.msdn.microsoft.com/webdev/2018/02/28/asp-net-core-2-1-preview1-introducing-httpclient-factory/"&gt;HttpClientFactory introduced in ASP.NET Core 2.1&lt;/a&gt; provides a convenient way to consolidate the URLs for various services used by our application.&lt;/p&gt; &lt;p&gt;.NET Core has no public API to work with the certificate format provided by OpenShift. To read those certificates, we’ll add a dependency on the &lt;code&gt;Portable.BountyCastle&lt;/code&gt; package:&lt;/p&gt; &lt;pre&gt;&amp;#60;PackageReference Include="Portable.BouncyCastle" Version="1.8.2" /&amp;#62; &lt;/pre&gt; &lt;p&gt;Next, we’ll add &lt;a href="https://raw.githubusercontent.com/redhat-developer/s2i-dotnetcore-ex/dotnetcore-2.1-https/app/OpenShift.cs"&gt;OpenShift.cs&lt;/a&gt; to our application and with a one-liner we can configure our application to use the OpenShift HTTPS certificate. When the service certificate expires, the application will terminate and OpenShift will restart it with a renewed certificate. As part of the one-liner, we set the &lt;code&gt;CertificateMountPoint&lt;/code&gt; property to the mount point of the secret that contains the OpenShift generated certificate:&lt;/p&gt; &lt;pre&gt;public static IWebHostBuilder CreateWebHostBuilder(string[] args) =&amp;#62; WebHost.CreateDefaultBuilder(args) .UseOpenShiftIntegration(_ =&amp;#62; _.CertificateMountPoint = "/var/run/secrets/service-cert") .UseStartup(); &lt;/pre&gt; &lt;p&gt;That covers the changes to our ASP.NET application. For the OpenShift configuration, we’ll use a template: &lt;a href="https://raw.githubusercontent.com/redhat-developer/s2i-dotnetcore-ex/dotnetcore-2.1-https/dotnet-example-https.json"&gt;dotnet-example-https.json&lt;/a&gt;. This template can be imported using the OpenShift Console or via the CLI command &lt;code&gt;oc create -f &amp;#60;url&amp;#62;&lt;/code&gt;. It has the following changes compared to a plain HTTP application:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The service has a &lt;code&gt;service.alpha.openshift.io/serving-cert-secret-name&lt;/code&gt; annotation.&lt;/li&gt; &lt;li&gt;The container spec defines and mounts the certificate secret.&lt;/li&gt; &lt;li&gt;The liveness and readiness probes use the HTTPS scheme.&lt;/li&gt; &lt;li&gt;The route is configured for TLS passthrough.&lt;/li&gt; &lt;li&gt;&lt;code&gt;DOTNET_SSL_DIRS&lt;/code&gt; is set to trust the cluster certificate authority bundle.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;An internal service shouldn&amp;#8217;t have a route (this is for public access). It is part of the template, so we can look at the certificate with our browser.&lt;/p&gt; &lt;p&gt;Once we’ve imported the template, we can add it via &lt;strong&gt;Add to Project &amp;#62; Select from Project &amp;#62; .NET Core HTTPS Example. &lt;/strong&gt;In the configuration step, we can change parameters like the Git repository that contains our source code.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image1.png"&gt;&lt;img class=" aligncenter wp-image-517407 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image1.png" alt="Select from Project screen" width="905" height="676" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image1.png 905w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image1-300x224.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image1-768x574.png 768w" sizes="(max-width: 905px) 100vw, 905px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the Overview page, we can track the progress of the S2I build and deployment. When our application is up and running, we click the HTTPS URL of the route. In the browser, we’ll get a warning about the certificate. This is expected: we get the internal service certificate, which isn’t trusted by our browser and doesn’t match the hostname.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image3.png"&gt;&lt;img class=" aligncenter wp-image-517387 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image3.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image3.png" alt="Warning about the certificate" width="646" height="211" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image3.png 646w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image3-300x98.png 300w" sizes="(max-width: 646px) 100vw, 646px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the error message, we see the certificate is for the internal service name (in this case, &lt;code&gt;dotnet-https-example.demo.svc&lt;/code&gt;). The issuer (unknown to our browser) is the internal cluster certificate authority.&lt;/p&gt; &lt;p&gt;If we tell the browser to accept the certificate, we&amp;#8217;ll see our ASP.NET Core application up and running and terminating SSL using the OpenShift service certificate!&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image2.png"&gt;&lt;img class=" aligncenter wp-image-517397 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image2.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image2.png" alt="ASP.NET Core application running" width="841" height="615" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image2.png 841w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image2-300x219.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image2-768x562.png 768w" sizes="(max-width: 841px) 100vw, 841px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the previous section, we let OpenShift terminate SSL for our route using &lt;em&gt;edge&lt;/em&gt; termination. With our current configuration, we are terminating SSL directly in our ASP.NET Core application using &lt;em&gt;passthrough&lt;/em&gt;. Another option is to do both: OpenShift terminates SSL with the public certificate and internally we use service certificates. This is the &lt;em&gt;Re-encrypt&lt;/em&gt; configuration.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image5.png"&gt;&lt;img class=" aligncenter wp-image-517367 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image5.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image5.png" alt="Re-encrypt configuration" width="339" height="169" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image5.png 339w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image5-300x150.png 300w" sizes="(max-width: 339px) 100vw, 339px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When we change to re-encrypt our demo site, which is deployed on &lt;a href="https://www.openshift.com/products/online/"&gt;Red Hat OpenShift Online&lt;/a&gt;, it will use the router wildcard certificate. This certificate is trusted by the browser.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image6.png"&gt;&lt;img class=" aligncenter wp-image-517357 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image6.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image6.png" alt="Re-encrypted our demo site" width="696" height="38" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/image6.png 696w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/image6-300x16.png 300w" sizes="(max-width: 696px) 100vw, 696px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;In this blog post, you’ve learned how to secure your ASP.NET Core applications on OpenShift using HTTPS. We’ve looked at terminating SSL in OpenShift for public routes and at terminating SSL in ASP.NET Core directly using OpenShift-generated service certificates.&lt;/p&gt; &lt;p&gt;For more information about running .NET Core on OpenShift, see the &lt;a href="https://access.redhat.com/documentation/en-us/net_core/2.1/html/getting_started_guide/gs_dotnet_on_openshift"&gt;.NET Core 2.1 getting started guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;There are also other &lt;a href="https://developers.redhat.com/blog/category/security/"&gt;security topics&lt;/a&gt; on the Red Hat Developer blog.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;linkname=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F12%2Fsecuring-net-core-on-openshift-using-https%2F&amp;#38;title=Securing%20.NET%20Core%20on%20OpenShift%20using%20HTTPS" data-a2a-url="https://developers.redhat.com/blog/2018/10/12/securing-net-core-on-openshift-using-https/" data-a2a-title="Securing .NET Core on OpenShift using HTTPS"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/12/securing-net-core-on-openshift-using-https/"&gt;Securing .NET Core on OpenShift using HTTPS&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/4eWG9sB2j6Y" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In an effort to improve security, browsers have become stricter in warning users about sites that aren&amp;#8217;t properly secured with SSL/TLS. ASP.NET Core 2.1 has improved support for HTTPS. You can read more about these enhancements in Improvements to using HTTPS. In this blog post, we’ll look at how you can add HTTPS to your ASP.NET [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/12/securing-net-core-on-openshift-using-https/"&gt;Securing .NET Core on OpenShift using HTTPS&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/10/12/securing-net-core-on-openshift-using-https/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">517327</post-id><dc:creator>Tom Deseyn</dc:creator><dc:date>2018-10-12T11:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/12/securing-net-core-on-openshift-using-https/</feedburner:origLink></entry><entry><title>Handle service exceptions via subprocess</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gqlbAsLWQvI/handle-service-exceptions-via-subprocess.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="jbpm_error_hanlding" scheme="searchisko:content:tags" /><category term="jbpm_work_items" scheme="searchisko:content:tags" /><category term="work_item_handler_exceptions" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-handle_service_exceptions_via_subprocess</id><updated>2018-10-11T09:58:28Z</updated><published>2018-10-11T09:58:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Interacting with services as part of your business process (or in more general business automation) is a common requirement. Though we all know that services tend to fail from time to time and business automation solutions should be able to cope with that. A worth reading article was recently published by &lt;a href="https://github.com/dmarrazzo"&gt;Donato Marrazzo&lt;/a&gt; and can be found here&amp;nbsp;&lt;a href="https://developers.redhat.com/blog/2018/08/22/reducing-data-inconsistencies-with-red-hat-process-automation-manager/"&gt;Reducing data inconsistencies with Red Hat Process Automation Manager&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Described feature in this article was actually inspired by discussion with Donato so all credit goes to him!&lt;br /&gt;&lt;br /&gt;BPMN2 has already a construct for similar thing - error boundary events that can be easily attached to service tasks to deal with exceptions and perform additional processing or decision taking. This approach has some drawbacks in more advanced scenarios&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;error handling needs to be done on individual task level&lt;/li&gt;&lt;li&gt;retry of the same service call needs to be done via process modelling - usually a loop&lt;/li&gt;&lt;li&gt;each error type needs to be handled separately and by that makes the process definition too verbose&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;The first point from the above list can be addressed by using even based subprocess that starts with error event but that still suffers from the two other points.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;To address this an additional error handling is introduced (in jBPM version 7.13) that allows the work item handlers (that implement the logic responsible for service interaction) to throw special type of exception&amp;nbsp;&lt;span style="font-family: &amp;quot;menlo&amp;quot;; font-size: 12px;"&gt;org.kie.api.runtime.process.ProcessWorkItemHandlerException&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This exception requires three parameters&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;process id that should be created to deal with this exception&lt;/li&gt;&lt;li&gt;selected handling strategy to be applied when exception handling process is completed&lt;/li&gt;&lt;li&gt;root cause exception&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;When such exception is thrown from work item handler it triggers automatic error handling by starting subprocess instance with the definition identified by process id set on the exception. If the process is straight through (meaning does not have any wait states) service task that failed will apply the handling strategy directly, otherwise it puts the service task in a wait state until the subprocess instance is completed. Then the strategy is applied on the service task.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;Supported strategies&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;There are four predefined strategies&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;b&gt;COMPLETE&lt;/b&gt; - it completes the service task with the variables from the completed subprocess instance - these variables will be given to the service task as output of the service interaction and thus mapped to main process instance variables&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; - it aborts the service task and moves on the process without setting any variables&lt;/li&gt;&lt;li&gt;&lt;b&gt;RETRY&lt;/b&gt; - it retries the service task logic (calls the work item handler again) with variables from both the original service task parameters and the variables from subprocess instance - variables from subprocess instance overrides any variables of the same name&lt;/li&gt;&lt;li&gt;&lt;b&gt;RETHROW&lt;/b&gt; - it simply throws the error back to the caller - &lt;span style="color: red;"&gt;this strategy should not be used with wait state subprocesses as it will simply rollback the transaction and thus the completion of the subprocess instance&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;With this feature service implementors (those who implement work item handlers) can simply decide how the exception should be handled and what strategy it should apply to the failing service tasks once the error was evaluated and fixed.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Out of the box handlers and exception handling&lt;/h3&gt;Three major out of the box work item handlers are equipped with this handling automatically as soon as they are created with process id to handle exception and strategy. This takes over the regular error handling that will be applied when RETHROW strategy is selected.&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;RESTWorkItemHandler&lt;/li&gt;&lt;li&gt;WebServiceWorkItemHandler&lt;/li&gt;&lt;li&gt;EmailWorkItemHandler&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Sample registration for RESTWorkItemHandler via deployment descriptor would be&lt;br /&gt;&lt;br /&gt;&lt;pre class="brush:java"&gt;new org.jbpm.process.workitem.rest.RESTWorkItemHandler("username", "password", classLoader, "handlingProcessId", "handlingStrategy")&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;Look at available constructors of given handler class to see all possible options. Similar way email and Webservice handlers can be configured to handle the exceptions via subprocess.&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Use cases&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;Here are few examples that could be implemented&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;report to administrator that service task failed - this would have to be via subprocess that has user task assigned to administrators&amp;nbsp;&lt;/li&gt;&lt;li&gt;use a timer based sub process to introduce some delay in retries&lt;/li&gt;&lt;li&gt;ask business users to provide the information in case system is down in time critical situations&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;There can be many more use cases implemented by that and one of the most important things with this is it does not have to be modelled for each and every task that could fail. It is up to the service handler to instruct what and how should be done in case of errors.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;In action...&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;A short screencast showing this in action, simple process with custom service task that has a work item handler that throws&amp;nbsp;&lt;span style="font-family: &amp;quot;menlo&amp;quot;; font-size: 12px;"&gt;ProcessWorkItemHandlerException&lt;/span&gt;&amp;nbsp;exception and starts user focused subprocess to provide expected values and then apply COMPLETE strategy.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/lLfPJShsf54" width="560"&gt;&lt;/iframe&gt; &lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://github.com/mswiderski/handling-wih-exception"&gt;Here&lt;/a&gt; is the complete sample repository shown in the above screencast.&lt;br /&gt;&lt;br /&gt;Hopefully you will find this useful and that will allow you to better automate your business to avoid any repetitive actions ... &lt;br /&gt;&lt;br /&gt;Visit &lt;a href="http://jbpm.org/"&gt;jbpm.org&lt;/a&gt; to download latest version of the jBPM project&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gqlbAsLWQvI" height="1" width="1" alt=""/&gt;</content><summary>Interacting with services as part of your business process (or in more general business automation) is a common requirement. Though we all know that services tend to fail from time to time and business automation solutions should be able to cope with that. A worth reading article was recently published by Donato Marrazzo and can be found here Reducing data inconsistencies with Red Hat Process Auto...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-10-11T09:58:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/10/handle-service-exceptions-via-subprocess.html</feedburner:origLink></entry><entry><title>Infinispan Spring Boot 2.0.0.Final is out!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1gXGsVDz8Io/infinispan-spring-boot-200final-is-out.html" /><category term="2.0.0.Final" scheme="searchisko:content:tags" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="Spring" scheme="searchisko:content:tags" /><category term="spring-boot" scheme="searchisko:content:tags" /><category term="spring-boot starters" scheme="searchisko:content:tags" /><author><name>Katia Aresti</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_spring_boot_2_0_0_final_is_out</id><updated>2018-10-12T12:45:06Z</updated><published>2018-10-11T07:51:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Dear Infinispan and Spring Boot users,&lt;br /&gt;&lt;br /&gt;We have just released &lt;a href="https://github.com/infinispan/infinispan-spring-boot" target="_blank"&gt;Infinispan Spring Boot&lt;/a&gt;&amp;nbsp;&lt;b&gt;2.0.0.Final&lt;/b&gt;.&lt;br /&gt;If you are wondering why it is worth to use this starter, read Sebastian's article &lt;a href="https://blog.infinispan.org/2016/12/spring-boot-starters.html" target="_blank"&gt;here&lt;/a&gt;!&lt;br /&gt;&lt;br /&gt;Highlights of this release include:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Uses the latest Infinispan &lt;a href="https://blog.infinispan.org/2018/10/infinispan-940final.html"&gt;9.4.0.Final&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Automatic translation of Hot Rod client properties into Spring YAML (&lt;a href="https://issues.jboss.org/browse/ISPN-9437"&gt;ISPN-9437&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Bug fixes&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;br /&gt;You can find the release in the maven central repository.&lt;br /&gt;&lt;br /&gt;Please report any issues in our&amp;nbsp;&lt;a href="https://issues.jboss.org/projects/ISPN"&gt;issue tracker&lt;/a&gt;&amp;nbsp;and join the conversation in our&amp;nbsp;&lt;a href="https://infinispan.zulipchat.com/"&gt;Zulip Chat&lt;/a&gt;&amp;nbsp;to shape up our next release.&lt;br /&gt;&lt;br /&gt;Enjoy,&lt;br /&gt;&lt;br /&gt;The Infinispan Team&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/c-EJ1EH7v5A" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1gXGsVDz8Io" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan and Spring Boot users, We have just released Infinispan Spring Boot 2.0.0.Final. If you are wondering why it is worth to use this starter, read Sebastian's article here! Highlights of this release include: Uses the latest Infinispan 9.4.0.Final Automatic translation of Hot Rod client properties into Spring YAML (ISPN-9437) Bug fixes You can find the release in the maven central rep...</summary><dc:creator>Katia Aresti</dc:creator><dc:date>2018-10-11T07:51:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/c-EJ1EH7v5A/infinispan-spring-boot-200final-is-out.html</feedburner:origLink></entry><entry><title>Use Groovy to customize the Maven build process</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/N--ftreF98w/" /><category term="Java" /><category term="JBoss Fuse" /><category term="Modern App Dev" /><category term="build process" /><category term="Fuse online" /><category term="GMaven" /><category term="Groovy" /><category term="maven" /><category term="plugin" /><category term="software build" /><author><name>Andrea Tarocchi</name></author><id>https://developers.redhat.com/blog/?p=522147</id><updated>2018-10-10T11:00:16Z</updated><published>2018-10-10T11:00:16Z</published><content type="html">&lt;p&gt;&lt;a href="https://maven.apache.org"&gt;Apache Maven&lt;/a&gt; is a popular build automation tool used primarily for Java projects (although it can also be used to build and manage projects written in other languages). Maven uses a &lt;code&gt;pom.xml&lt;/code&gt; file to centrally manage a project&amp;#8217;s build and its dependencies. If you have worked anywhere near to the &lt;a href="https://developers.redhat.com/blog/category/java/"&gt;Java ecosystem&lt;/a&gt; chances are that, for the good or for the bad, you have come across the use of this tool.&lt;/p&gt; &lt;p&gt;Maven plugins are used to enhance and customize the Maven build process; while the &lt;a href="https://maven.apache.org/plugins/"&gt;list of existing plugins&lt;/a&gt; is quite extensive, it is common to need to implement some small changes or tweak the build just a bit, which makes writing a whole plugin feel like overkill.&lt;/p&gt; &lt;p&gt;This post describes a possible solution: the &lt;a href="https://github.com/groovy/GMavenPlus"&gt;GMaven Plus plugin&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-522147"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;GMaven Plus is a Maven plugin for managing Groovy projects with Maven. Among other features, it has an execute script goal that can be configured easily, as shown in the following snippet:&lt;/p&gt; &lt;pre&gt;&amp;#60;build&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.codehaus.gmavenplus&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;gmavenplus-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;1.6.1&amp;#60;/version&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;execute&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;properties&amp;#62; &amp;#60;property&amp;#62; &amp;#60;name&amp;#62;someProp&amp;#60;/name&amp;#62; &amp;#60;value&amp;#62;${someProp}&amp;#60;/value&amp;#62; &amp;#60;/property&amp;#62; &amp;#60;/properties&amp;#62; &amp;#60;scripts&amp;#62; //your Groovy code goes here &amp;#60;/scripts&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;dependencies&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;org.codehaus.groovy&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;groovy-all&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;2.5.0&amp;#60;/version&amp;#62; &amp;#60;type&amp;#62;pom&amp;#60;/type&amp;#62; &amp;#60;scope&amp;#62;runtime&amp;#60;/scope&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;/dependencies&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &lt;/pre&gt; &lt;p&gt;The execution of the Groovy script can be bound to any Maven phase; furthermore, inside the script, the objects &lt;code&gt;session&lt;/code&gt; and &lt;code&gt;project&lt;/code&gt; can be used to interact with the Maven build. For instance, the project name can be logged with &lt;code&gt;log.info "$project.name"&lt;/code&gt;. (There are other useful Maven objects available to be used in the Groovy script along with other useful goodies like using &lt;code&gt;@Grab&lt;/code&gt; to download external dependencies your script might have; check the &lt;a href="https://github.com/groovy/GMavenPlus/wiki/Examples#execute-scripts"&gt;examples&lt;/a&gt;). Due to the combination of these two capabilities, it is quite easy to extend the Maven build process directly with an inline Groovy script placed directly in the &lt;code&gt;pom.xml&lt;/code&gt; file, as shown above.&lt;/p&gt; &lt;h2&gt;A real-world example&lt;/h2&gt; &lt;p&gt;Instead of using a fictional example to showcase how to use the GMaven Plus plugin for our purposes, I think it would be beneficial to look at a real-world example. The example is taken from the &lt;a href="https://syndesis.io/" target="_blank" rel="noopener"&gt;Syndesis&lt;/a&gt; project.&lt;/p&gt; &lt;p&gt;Syndesis is an integration Platform-as-a-Service (iPaaS) that aims to simplify collaboration between business users, integration experts, and application developers. It is a cloud-native toolchain and runtime, available right from your browser. It is an open source project on which &lt;a href="https://developers.redhat.com/products/fuse/overview/"&gt;Red Hat Fuse Online&lt;/a&gt; is based.&lt;/p&gt; &lt;figure&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47.png"&gt;&lt;img class=" aligncenter wp-image-524207 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47-1024x515.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47.png" alt="Syndesis dashboard" width="2536" height="1275" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47.png 2536w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47-768x386.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-11-45-47-1024x515.png 1024w" sizes="(max-width: 2536px) 100vw, 2536px" /&gt;&lt;/a&gt;&lt;figcaption&gt;Syndesis dashboard&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Using just the Syndesis web UI, it is possible to define, run, and manage an integration that, for instance, takes data from Twitter and saves it in a database or sends a message to a messaging system like Apache Kafka or Apache ActiveMQ. These tasks historically required an integration specialist and a developer to work together, sometimes for days, but with Syndesis these tasks can be accomplished in a no-code fashion directly by a business user.&lt;/p&gt; &lt;figure&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34.png"&gt;&lt;img class=" aligncenter wp-image-524217 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34-1024x292.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34.png" alt="Syndesis integration editor" width="2525" height="721" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34.png 2525w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34-300x86.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34-768x219.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-from-2018-10-04-12-31-34-1024x292.png 1024w" sizes="(max-width: 2525px) 100vw, 2525px" /&gt;&lt;/a&gt;&lt;figcaption&gt;Syndesis integration editor&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;The platform is extensible through extensions to cover less-standard and more-particular cases (some extensions are collected in their own &lt;a href="https://github.com/syndesisio/syndesis-extensions"&gt;GitHub repository&lt;/a&gt;). Usually, it is a developer that takes care of creating such an extension and building it. In order to do so, the extensions must be built against the version of the Syndesis platform on which they will be loaded. Manually retrieving and setting the Syndesis version in the syndesis-extension project is a tedious and error-prone activity. It would be much better if you could pass the Syndesis platform URL to the build process and Maven would automatically get the right version and use it.&lt;/p&gt; &lt;h2&gt;Solution explained&lt;/h2&gt; &lt;p&gt;The Groovy script in &lt;a href="https://github.com/syndesisio/syndesis-extensions/blob/af61fb81c74ce02cc4cd63451eca4620e8718c46/pom.xml#L114-L180"&gt;syndesis-extension project pom.xml&lt;/a&gt; implements the following logic: the URL is passed in a property named &lt;code&gt;syndesisServerUrl&lt;/code&gt; that is used to dynamically retrieve the Syndesis version and set it as &lt;code&gt;syndesis.version&lt;/code&gt; in the Maven project. If no URL is provided, Maven will fall back to using the &lt;code&gt;syndesis.version&lt;/code&gt; present in the &lt;code&gt;pom.xml&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;The relevant part of the &lt;code&gt;pom.xml&lt;/code&gt; file is shown below:&lt;/p&gt; &lt;pre&gt;&amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.codehaus.gmavenplus&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;gmavenplus-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;1.6&amp;#60;/version&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;id&amp;#62;get-syndesis-version&amp;#60;/id&amp;#62; &amp;#60;phase&amp;#62;initialize&amp;#60;/phase&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;execute&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;scripts&amp;#62; &amp;#60;script&amp;#62; [...] log.debug "START getting syndesis version from a running Syndesis server." def syndesisServerUrl = getPropertyValue('syndesisServerUrl') log.debug "syndesisServerUrl value = $syndesisServerUrl" if( syndesisServerUrl != null ) { [...] String syndesisVersionUrl = syndesisServerUrl+"/api/v1/version" log.info "About to call GET on $syndesisVersionUrl" def version = null try { version = new URL(syndesisVersionUrl).getText(requestProperties: [Accept: 'text/plain']) String syndesisVesrion = new String(version) project.properties.setProperty('syndesis.version', syndesisVesrion) log.info "syndesis.version set to: $syndesisVesrion" } catch(Exception ex) { log.error "Error during syndesis version GET from $syndesisVersionUrl" ex.printStackTrace() throw ex } finally { log.info "Called GET on $syndesisVersionUrl with result $version" } } else { log.info "syndesisServerUrl property not set, the syndesis.version from pom.xml will be used." } [...] String getPropertyValue(String name) { def value = session.userProperties[name] if (value != null) return value //property was defined from command line e.g.: -DpropertyName=value return project.properties[name] } log.debug "END getting syndesis version from a running Syndesis server." &amp;#60;/script&amp;#62; &amp;#60;/scripts&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;dependencies&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;org.codehaus.groovy&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;groovy-all&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;2.4.12&amp;#60;/version&amp;#62; &amp;#60;scope&amp;#62;runtime&amp;#60;/scope&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;/dependencies&amp;#62; &amp;#60;/plugin&amp;#62; &lt;/pre&gt; &lt;p&gt;The above snippet highlights crucial lines. First off, the line &lt;code&gt;&amp;#60;phase&amp;#62;initialize&amp;#60;/phase&amp;#62;&lt;/code&gt; binds the script execution to the initialization phase; hence, it will be executed at the beginning of each Maven build. The rest of the script is a self-explanatory Groovy code implementation of the logic described at the beginning of this section. Perhaps the most crucial line is &lt;code&gt;project.properties.setProperty('syndesis.version', syndesisVersion&lt;/code&gt;, which sets the &lt;code&gt;syndesis.version&lt;/code&gt; property in the Maven &lt;code&gt;project&lt;/code&gt; object. In this way, if a user invokes the build with &lt;code&gt;mvn clean install -DsyndesisServerUrl=https://your.syndesis.server.url&lt;/code&gt;, the Syndesis version is dynamically taken from the provided URL.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article presented a way to use the GMaven Plus plugin to tap into a Maven build and interact with it without the need to write a whole Maven plugin. Furthermore, it presented and commented on a real-world usage of that technique in order to provide some context to the discussion.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;linkname=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F10%2Fgroovy-customize-maven-build%2F&amp;#38;title=Use%20Groovy%20to%20customize%20the%20Maven%20build%20process" data-a2a-url="https://developers.redhat.com/blog/2018/10/10/groovy-customize-maven-build/" data-a2a-title="Use Groovy to customize the Maven build process"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/10/groovy-customize-maven-build/"&gt;Use Groovy to customize the Maven build process&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/N--ftreF98w" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Apache Maven is a popular build automation tool used primarily for Java projects (although it can also be used to build and manage projects written in other languages). Maven uses a pom.xml file to centrally manage a project&amp;#8217;s build and its dependencies. If you have worked anywhere near to the Java ecosystem chances are that, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/10/groovy-customize-maven-build/"&gt;Use Groovy to customize the Maven build process&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/10/10/groovy-customize-maven-build/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">522147</post-id><dc:creator>Andrea Tarocchi</dc:creator><dc:date>2018-10-10T11:00:16Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/10/groovy-customize-maven-build/</feedburner:origLink></entry></feed>
